name: ML Pipeline

on:
  push:
    branches: [main, develop]
    paths: ["src/**", "configs/**", "data/**", "requirements.txt"]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  data-validation:
    runs-on: ubuntu-latest
    outputs:
      data-changed: ${{ steps.check-data.outputs.changed }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Check if data files changed
        id: check-data
        run: |
          if git diff --name-only HEAD^ HEAD | grep -E "(data/|configs/|src/)" || [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "changed=true" >> $GITHUB_OUTPUT
          else
            echo "changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Python
        if: steps.check-data.outputs.changed == 'true'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        if: steps.check-data.outputs.changed == 'true'
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate data integrity
        if: steps.check-data.outputs.changed == 'true'
        run: |
          python -c "
          import pandas as pd
          import sys
          try:
              data = pd.read_csv('data/raw/house_data.csv')
              if len(data) < 50:
                  print('ERROR: Insufficient data samples')
                  sys.exit(1)
              if data.isnull().sum().sum() > len(data) * 0.7:
                  print('ERROR: Too many missing values')
                  sys.exit(1)
              print(f'Data validation passed: {len(data)} samples')
          except Exception as e:
              print(f'Data validation failed: {e}')
              sys.exit(1)
          "

  ml-pipeline:
    needs: data-validation
    if: needs.data-validation.outputs.data-changed == 'true'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

          # Ensure MLflow and Databricks packages are installed for CI
          pip install mlflow==2.3.1 databricks-cli==0.18.0 databricks-sdk==0.12.0

      - name: Configure Databricks MLflow
        env:
          DATABRICKS_HOST: ${{ vars.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          MLFLOW_TRACKING_URI: ${{ vars.MLFLOW_TRACKING_URI }}
        run: |
          rm -rf ~/.databrickscfg
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = $DATABRICKS_HOST
          token = $DATABRICKS_TOKEN
          EOF

          python -c "
          import mlflow
          import os
          os.environ['DATABRICKS_HOST'] = os.getenv('DATABRICKS_HOST')
          os.environ['DATABRICKS_TOKEN'] = os.getenv('DATABRICKS_TOKEN')
          mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI'))
          experiments = mlflow.search_experiments()
          print(f'Connected to MLflow: {len(experiments)} experiments found')
          "

      - name: Create necessary directories
        run: |
          mkdir -p data/processed
          mkdir -p models/trained
          mkdir -p logs

      - name: Run ML Pipeline
        id: pipeline
        env:
          MLFLOW_TRACKING_URI: ${{ vars.MLFLOW_TRACKING_URI }}
        run: |
          python src/pipeline/orchestrator.py \
            --config configs/model_config.yaml \
            --mlflow-uri "${MLFLOW_TRACKING_URI}"

      - name: Upload Model Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-artifacts
          path: |
            models/trained/
            configs/model_config.yaml

  build-and-push:
    needs: ml-pipeline
    if: success() && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-artifacts
          path: ./

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION || 'eu-west-1' }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push API image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY_API: ${{ vars.ECR_REPOSITORY_API || 'house-price-api' }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Build API image
          docker build -f Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY_API:$IMAGE_TAG .
          docker build -f Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY_API:latest .

          # Push API image
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_API:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_API:latest

          echo "API image pushed: $ECR_REGISTRY/$ECR_REPOSITORY_API:$IMAGE_TAG"

      - name: Build and push UI image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY_UI: ${{ vars.ECR_REPOSITORY_UI || 'house-price-ui' }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          # Build UI image
          docker build -f streamlit_app/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY_UI:$IMAGE_TAG ./streamlit_app
          docker build -f streamlit_app/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY_UI:latest ./streamlit_app

          # Push UI image
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_UI:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY_UI:latest

          echo "UI image pushed: $ECR_REGISTRY/$ECR_REPOSITORY_UI:$IMAGE_TAG"

  notify:
    needs: [data-validation, ml-pipeline, build-and-push]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Pipeline Status
        run: |
          if [ "${{ needs.ml-pipeline.result }}" == "success" ] && [ "${{ needs.build-and-push.result }}" == "success" ]; then
            echo "✅ Pipeline completed successfully"
          else
            echo "❌ Pipeline failed"
            exit 1
          fi
